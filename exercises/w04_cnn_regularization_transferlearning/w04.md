
# Exercise week 4

Welcome to the course Advanced Machine Learning! This is your forth mandatory exercise which must be completed until next week, 27.09.2022, 14:00. By that time you must fill out the checklist on the learnit page to indicate which tasks you completed and volunteer to present. 

## Task 1: Understanding filters for CNNs

We start this week's exercises with building up some technical expertise of 1) how some simple filters could be defined and work, and 2) how to advance last week's MLP on simple image classification. 

<ol type ="a">
 <li>Go through the <b>w04_filters.ipynb</b> notebook and build up a basic understanding of how filters work. Take your time here, as this is an important step in your learning.</li>
 <li>Go through the <b>w04_cnn_mnist_pytorch.ipynb</b> notebook and understand the individual steps (as an alternative, you can take your tensorflow MLP work from last week and replace the dense layers by convolution analogue to the pytorch example). Is The CNN better than the MLP trained in the notebook from exercise 3.4? What differences in results have you found?</li>
</ol>

## Task 2: Practising applying a CNN to image date and visualising results

The goal of this exercise is to expand your understanding of implementing neural network architectures and training methods in the tensorflow or pytorch frameworks, and on the way, get to know interesting tasks and datasets as well as practising visualisation options. In particular, we look into CIFAR10 in order to get a better insight into building up a filter hierarchy with CNNs.

For this exercise you can use the prepared stub **w04_cnn_mnist_pytorch.ipynb**. Alternatively reuse and reimplement the data loading in a tensorflow implementation if you prefer this framework.

<ol type ="a">
 <li>Read up on the CIFAR10 dataset: https://www.cs.toronto.edu/~kriz/cifar.html</li>
 <li>Re-implement a CNN for classification as you have seen in the Exercise 4.1 (feel free to copy+paste from there or online sources, as long as you understand what you are doing).</li>
 <li>Plot some data characteristics (samples, class distributions, or anything that you find useful to understand the data better). What is your most peculiar observation?</li>
 <li>Plot some training progress (loss and accuracy)
Plot some model analyses (confusion matrix and accuracy on the test dataset). Are there classes that are difficult to classify correctly?</li>
 <li>Have a brief (!) experiment with different settings for the hyperparameters: batch_size, learning_rate, number & size of CNN layers, and filters (e.g. kernel_size). What is the best setup according to the best accuracy that you could find? </li>
</ol>

## Task 3: Theory and praxis of Regularization

To understand regularization, we need to grasp the essence of the L1 and L2 formalisation in small and experience the effect of either regularisation (L1/L2, Dropout, ...) in large. So as a first step we just revisit the definition and effect of regularization with the L1 norm (lasso) and L2 norm (ridge).

<ol type ="a">
 <li>Remember the penalty terms in $L_1$ regularization: $||\boldsymbol w||_1 = {|w_1| + |w_2| + ... + |w_n|}$

  and in $L_2$ regularization: $||\boldsymbol w||_2^2 = w_1^2 + w_2^2 + ... + w_n^2$
  
  Now consider a model with the following weights: $\{w_1 = 0.2, w_2 = 0.5, w_3 = 5, w_4 = 1, w_5 = 0.25, w_6 = 0.75\}$ 
  
  As a simple warm up: what are the value of the $L_1$ and $L_2$ penalties, respectively? Now discuss: what is the effect of these different penalties e.g. on a uniformly distributed vs. on a normal distributed weight matrices (and the weight updates respectively).
 </li>
 <li>Consider again the simulation example from the lecture: 

[playground.tensorflow.org](https://playground.tensorflow.org/#activation=tanh&batchSize=4&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0.003&noise=40&networkShape=6,5,5&seed=0.54350&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false). 

Compare L1 vs L2 regularization with different rates until you stop overfitting. What is the effect of very small and very large regularization rates on the weight matrices?
 </li>
</ol>

As second step, we want to build up an intuition how dropout works and impacts the training, via
https://colab.research.google.com/drive/14K0xiTb5GzygPTvRIWLz8UQwrb2O5UGZ

<ol type ="a" start="3">
 <li>Retrace how dropout is built in:
  - How is it used in the layer(s)?
  - How are the random dropouts generated?</li>

 <li>Test using dropout in different variations: 
  
  - Use it on different layers, i.e. only on one layer.
  - Use different dropout probabilities, e.g. from {0.1, 0.3, 0.5}, on all combinations of layers.

  How does this affect the training?</li>
 <li> Briefly (!) test the dropout variations with the CIFAR data (thus on your solution for Exercise 4.2). Are your observations similar?
</li>
</ol>

## Task 4: Understand Finetuning

Here we look now into transfer learning, particularly fine-tuning a general model for a specific downstream task, via
https://colab.research.google.com/github/probml/probml-notebooks/blob/master/notebooks-d2l/finetune_cnn_torch.ipynb

<ol type ="a">
 <li>Retrace how the pre-trained model is used in the new task to clarify and explore:

  - What is the strategy for fine-tuning?
  - What is the effect (on test accuracy) of using other learning-rate settings (for the fc layer)?</li>

 <li>Discuss and explore with your colleagues: 

  - What other strategies could be sensible?
  - What is the effect of these strategies, both on: absolute best accuracy and convergence time?
 </li>
</ol>

  
## Optional task 5: Explore Data Augmentation options and impact

Now with the interested students, we want to look into data augmentation functions in torchvision, via 
https://colab.research.google.com/drive/1vjJ028WDDvfIj8Z1yH1KG6wSepj66gUG

<ol type ="a">
 <li>Read up what transformation functions are implemented in torchvision and familiarise yourself with the arguments in using them.</li>

 <li>Implement data augmentation into one of the previous tasks (e.g. from 4.2 or 4.3). Realise an augmentation strategy that extends the dataset (consistently) into double, quadruple, or octuple the size by using different transformation steps. Explore:

  - Which transformations have a notable impact on the performance?
  - Are particular transformation settings useful? 
  - How is the computation time affected?
 </li>
 <li>*Expert task*: Research into automated augmentation libraries.</li>
</ol>


## Optional expert task 6: Explore transfer learning framework *SimCLR*

If you still have time and energy, then let's look into a tutorial on SimCLR. This tutorial is 3rd party/homebrew and not necessarily correct in every aspect, nevertheless it should give you some good insight.

Thus either via https://colab.research.google.com/github/keras-team/keras-io/blob/master/examples/vision/ipynb/semisupervised_simclr.ipynb (Tensorflow) or via 
https://colab.research.google.com/github/phlippe/uvadlc_notebooks/blob/master/docs/tutorial_notebooks/tutorial17/SimCLR.ipynb (PyTorch) explore constrastive learning to understand:

<ol type ="a">
 <li>How is similarity and constrast enforced?</li>
 <li>Did this tutorial raise any new question? -> bring them up in the lecture and/or group tutorial!</li>
</ol>
